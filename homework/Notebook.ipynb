{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ad8ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y limpiar los datos\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import json\n",
    "import gzip\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler,StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "# Leer los datos \n",
    "train_df = pd.read_csv(\"../files/input/train_data.csv.zip\")\n",
    "test_df = pd.read_csv(\"../files/input/test_data.csv.zip\")\n",
    "\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df.rename(columns={\"default payment next month\": \"default\"}, inplace=True)\n",
    "    df.drop(columns=[\"ID\"], inplace=True)\n",
    "    df.replace({\"EDUCATION\": {0: 4, 5: 4, 6: 4}, \"MARRIAGE\": {0: 3}}, inplace=True)\n",
    "    df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6874703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables predictoras\n",
    "\n",
    "X_train = train_df.drop(columns=[\"default\"])\n",
    "y_train = train_df[\"default\"]\n",
    "X_test = test_df.drop(columns=[\"default\"])\n",
    "y_test = test_df[\"default\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a23f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear el pipeline completo\n",
    "\n",
    "categorical_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('OneHotEncoder', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "def create_sample_weights(y):\n",
    "    class_counts = np.bincount(y)\n",
    "    total_samples = len(y)\n",
    "    weight_for_0 = total_samples / (2.0 * class_counts[0])\n",
    "    weight_for_1 = total_samples / (2.0 * class_counts[1]) * 1.8  # Factor de ajuste\n",
    "    return np.where(y == 0, weight_for_0, weight_for_1)\n",
    "\n",
    "sample_weights = create_sample_weights(y_train)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.70)),  # Reducción muy agresiva\n",
    "    ('selector', SelectKBest(f_classif, k=5)),  # Solo las 5 mejores features\n",
    "    ('classifier', MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),  # Arquitectura más simple\n",
    "        activation='tanh',\n",
    "        alpha=0.001,  # Mayor regularización\n",
    "        early_stopping=True,\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=2000,\n",
    "        random_state=42,\n",
    "        batch_size=256,\n",
    "        solver='adam'\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ada3893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "\n",
      "Precisión: 0.381\n",
      "Recall: 0.645\n",
      "Balanced Accuracy: 0.681\n"
     ]
    }
   ],
   "source": [
    "# Optimizar hiperparámetros con validación cruzada\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid={\n",
    "        'pca__n_components': [0.75, 0.80],\n",
    "        'classifier__alpha': [0.0003]\n",
    "    },\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='precision',  # Enfocado directamente en precisión\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train, classifier__sample_weight=sample_weights)\n",
    "\n",
    "# 4. Predicción con ajuste de threshold optimizado\n",
    "y_probs = grid_search.predict_proba(X_test)[:, 1]\n",
    "best_threshold = 0.62  # Threshold más alto para precisión\n",
    "y_pred_final = (y_probs > best_threshold).astype(int)\n",
    "\n",
    "# 5. Métricas finales\n",
    "print(f\"\\nPrecisión: {precision_score(y_test, y_pred_final):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_final):.3f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred_final):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea336d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Guardar el modelo entrenado\n",
    "\n",
    "model_path = \"../files/models/model.pkl.gz\"\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "with gzip.open(model_path, \"wb\") as f:\n",
    "    pickle.dump(grid_search, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c84c282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas\n",
    "\n",
    "y_pred_train = grid_search.predict(X_train)\n",
    "y_pred_test = grid_search.predict(X_test)\n",
    "\n",
    "def compute_metrics(y_true, y_pred, dataset_name):\n",
    "    return {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": dataset_name,\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"f1_score\": f1_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "metrics = [\n",
    "    compute_metrics(y_train, y_pred_train, \"train\"),\n",
    "    compute_metrics(y_test, y_pred_test, \"test\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd450e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calcular matrices de confusión y guardar \n",
    "def compute_confusion(y_true, y_pred, dataset_name):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    return {\n",
    "        \"type\": \"cm_matrix\",\n",
    "        \"dataset\": dataset_name,\n",
    "        \"true_0\": {\"predicted_0\": int(cm[0, 0]), \"predicted_1\": int(cm[0, 1])},\n",
    "        \"true_1\": {\"predicted_0\": int(cm[1, 0]), \"predicted_1\": int(cm[1, 1])},\n",
    "    }\n",
    "\n",
    "metrics.append(compute_confusion(y_train, y_pred_train, \"train\"))\n",
    "metrics.append(compute_confusion(y_test, y_pred_test, \"test\"))\n",
    "\n",
    "metrics_path = \"../files/output/metrics.json\"\n",
    "os.makedirs(os.path.dirname(metrics_path), exist_ok=True)\n",
    "\n",
    "with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in metrics:\n",
    "        json.dump(item, f)\n",
    "        f.write(\"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
